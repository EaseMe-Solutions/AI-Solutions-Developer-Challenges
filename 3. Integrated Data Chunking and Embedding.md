# Integrated Data Chunking and Embedding Challenge: Azure AI Search ğŸ“„ğŸ” â˜…â˜…â˜…â˜†

## Overview
Create an application that processes and searches documents using integrated data chunking and embedding with Azure AI Search. Utilize Azure's indexing capabilities to improve search efficiency and user experience.
UI is optional, since Azure AI Search can be queried via the Search Explorer of the created index.

## Technology Stack ğŸ› ï¸
* Azure AI Search
* OpenAI API (embeddings)
* (Optional) Next.js
* (Optional) TypeScript

## Project Requirements ğŸ“‹
1. **Data Chunking**:
   - Implement chunking logic that respects semantic boundaries for context preservation.

2. **Vectorization**:
   - Use OpenAI's API to convert text chunks into vectors.

3. **Search and Retrieval**:
   - Leverage Azure AI Search for indexing and querying vectorized data.
   - Implement logic to convert text queries to vectors and retrieve relevant chunks.

## Implementation Details ğŸ”

1. **Document Processing**:
   - Divide documents - stored in a Blob-Storage - into chunks suitable for embedding.

2. **Embedding and Storage**:
   - Use OpenAI's API to generate embeddings for each chunk.
   - Store these embeddings along with the chunks in Azure AI Search.

3. **Integration with Azure AI Search**:
   - Define **skillsets**:
     - a Text Split skill
     - AzureOpenAIEmbeddingModel or another embedding skill
   - Create an **index** to store vectorized content.
     - vectors field must be:
       - named "embedding"
       - searchable
       - retrievable
       - stored

   - Set up an **indexer** to process and enrich data using the skillsets every hour, using Blob-Storage **datasource**.

## Bonus Points â­
- User Interface:
  - Upload button to ingest text documents.
  - A text input for search queries.
  - A search button to initiate searches.
  - A display area to show search results and highlight matched terms.

## Evaluation Criteria ğŸ“Š

- **Effective Data Chunking**: Ensure document chunks are processed correctly with semantic boundaries.
- **Accurate Vectorization**: Proper use of OpenAI embeddings for generating vectors from document chunks.
- **Integration with Azure AI Search**: Successful setup and use of skillsets, indexers, and indexes.
- **Performance and Efficiency**: Responsiveness of document processing and search functionalities.
- **Code Quality**: Clarity, organization, and maintainability of the codebase.

## Reflections ğŸ¤”

- Which aspect of the project was most rewarding or challenging?
- What insights or improvements did you discover during implementation?
- If given more time, what additional features would you consider adding?
